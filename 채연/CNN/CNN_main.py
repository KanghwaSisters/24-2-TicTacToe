# -*- coding: utf-8 -*-
"""TTT_CNN.main.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PFVNt2dxbDQ8zInULR0PPeVsPK1Ilqia
"""

!pip install opencv-python

import cv2
cv2.__version__

import cv2
from google.colab.patches import cv2_imshow
import numpy as np
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/drive')

"""# Train Data Labeling"""

import cv2
import os
import json
from google.colab.patches import cv2_imshow

def split_image_into_cells(image_path):
    """
    이미지를 3x3 셀로 나누어 반환합니다.
    """
    image = cv2.imread(image_path)
    height, width, _ = image.shape
    cell_height, cell_width = height // 3, width // 3
    cells = [
        image[row * cell_height:(row + 1) * cell_height, col * cell_width:(col + 1) * cell_width]
        for row in range(3)
        for col in range(3)
    ]
    return cells

def label_cells(cells):
    cell_labels = []
    for idx, cell in enumerate(cells):
        resized_cell = cv2.resize(cell, (100,100))
        cv2_imshow(resized_cell)
        print(f"Label Cell {idx + 1}: (0 for O, 1 for X, 2 for blank)")
        key = input("Enter label (0/1/2):  ")  # 사용자 입력
        if key == '0':
            cell_labels.append("O")
        elif key == '1':
            cell_labels.append("X")
        elif key == '2':
            cell_labels.append("blank")
        else:
            print("Invalid input, defaulting to blank.")
            cell_labels.append("blank")
    return cell_labels

def save_labels_to_json(image_path, labels, output_dir):
    base_name = os.path.basename(image_path).split('.')[0]
    json_path = os.path.join(output_dir, f"{base_name}_labels.json")
    label_data = {f"cell_{i}": label for i, label in enumerate(labels)}
    with open(json_path, 'w') as json_file:
        json.dump(label_data, json_file)
    print(f"Labels saved to {json_path}")

# 라벨링 실행
image_dir = '/content/drive/MyDrive/kanghwa/ttt/image_black'
output_dir = '/content/drive/MyDrive/kanghwa/ttt/labels'
os.makedirs(output_dir, exist_ok=True)
image_files = sorted([f for f in os.listdir(image_dir) if f.endswith(('.JPG', '.jpg'))])


for image_file in image_files[-5:]:
    image_path = os.path.join(image_dir, image_file)
    cells = split_image_into_cells(image_path)
    resized_cells = [cv2.resize(cell, (100,100)) for cell in cells]
    labels = label_cells(cells)
    save_labels_to_json(image_path, labels, output_dir)

"""# Dataset"""

import os
from PIL import Image
import json

class TicTacToeCellDataset:
    def __init__(self, image_dir, label_dir, transform=None):
        self.image_dir = image_dir
        self.label_dir = label_dir
        self.transform = transform
        self.image_paths = []
        self.labels_paths = []

        # 이미지와 라벨 경로 확인
        image_files = [f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.JPG'))]
        label_files = [f for f in os.listdir(label_dir) if f.endswith(('.json'))]

        for image_file in image_files:
            base_name = os.path.splitext(image_file)[0]
            image_path = os.path.join(image_dir, image_file)
            possible_labels = [f for f in label_files if f.startswith(base_name) and ('_labels' in f)]
            for label_file in possible_labels:
                label_path = os.path.join(label_dir, label_file)
                self.image_paths.append(image_path)
                self.labels_paths.append(label_path)

        # 데이터셋의 길이 출력
        print(f"Found {len(self.image_paths)} images and {len(self.labels_paths)} labels.")

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        image_path = self.image_paths[idx]
        label_path = self.labels_paths[idx]

        # 이미지 로드
        image = Image.open(image_path).convert('RGB')

        # 라벨 로드
        with open(label_path, 'r') as f:
            label_data = json.load(f)

        # 'O' -> 1, 'X' -> -1, 'blank' -> 0
        label_mapping = {'O': 0, 'X': 1, 'blank': 2}
        # label_data의 각 셀을 숫자로 변환
        label_tensor = torch.tensor([label_mapping[label_data[f'cell_{i}']] for i in range(9)], dtype=torch.float32)

        # 변환 적용 (이미지 텐서로 변환)
        if self.transform:
            image = self.transform(image)

        return image, label_tensor

# blank, o, x 개수 파악
import os
import json
from collections import Counter

label_dir = '/content/drive/MyDrive/kanghwa/ttt/labels'
label_files = [os.path.join(label_dir, f) for f in os.listdir(label_dir) if f.endswith('.json')]
total_counts = Counter()

blank_count = 0
o_count = 0
x_count = 0

for file_path in label_files:
    with open(file_path, 'r') as f:
        labels = json.load(f)
        # 라벨 값만 가져와서 카운트
        total_counts.update(labels.values())
        blank_count += list(labels.values()).count('blank')
        o_count += list(labels.values()).count('O')
        x_count += list(labels.values()).count('X')

# 결과 출력
print("Label counts:")
print(f"blank: {blank_count}")
print(f"O: {o_count}")
print(f"X: {x_count}")

"""# Model(conv3)"""

import torch.nn as nn
import torch.nn.functional as F

class TicTacToeCNN(nn.Module):
    def __init__(self):
        super(TicTacToeCNN, self).__init__()
        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)
        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)
        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)
        self.bn1 = nn.BatchNorm2d(64)
        self.bn2 = nn.BatchNorm2d(128)
        self.bn3 = nn.BatchNorm2d(256)
        self.dropout = nn.Dropout(0.2)
        self.fc1 = nn.Linear(256*4*4, 128)
        self.fc2 = nn.Linear(128, 9*3)  # O, X, blank (3 classes)

    def forward(self, x):
        x = F.relu(self.bn1(self.conv1(x)))
        x = F.max_pool2d(x, 2)
        x = F.relu(self.bn2(self.conv2(x)))
        x = F.max_pool2d(x, 2)
        x = F.relu(self.bn3(self.conv3(x)))
        x = F.max_pool2d(x, 2)
        x = x.view(x.size(0), -1)
        x = self.dropout(x)
        x = self.fc2(x)

        x = x.view(x.size(0), 9, 3)
        return x

"""# Augmentation ver.
- blur
scaling
- rotation
- padding

## blur
"""

import os
import cv2
from tqdm import tqdm

# 원본 데이터 경로
data_path = '/content/drive/MyDrive/kanghwa/ttt/image_black'
file_list = [f for f in os.listdir(data_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

# Blur augmentation 적용
for file_name in tqdm(file_list, desc="Applying blur augmentation"):
    # 원본 이미지 경로
    img_path = os.path.join(data_path, file_name)

    # 이미지 읽기
    img = cv2.imread(img_path)
    if img is None:
        print(f"Failed to load {file_name}. Skipping...")
        continue

    # 가우시안 블러 적용
    blurred_img = cv2.GaussianBlur(img, (47,47), 0)

    # 블러 처리된 이미지 저장
    base_name, ext = os.path.splitext(file_name)
    blurred_output = os.path.join(data_path, f"{base_name}_blurred{ext}")
    cv2.imwrite(blurred_output, blurred_img)

print("Data augmentation completed!")

import os
import shutil
from tqdm import tqdm

# 원본 데이터 경로
data_path = '/content/drive/MyDrive/kanghwa/ttt/labels'

# 라벨 파일 리스트 불러오기
label_files = [f for f in os.listdir(data_path) if f.lower().endswith('.json')]

# 라벨 파일 복사
for label_file in tqdm(label_files, desc="Copying label files"):
    label_path = os.path.join(data_path, label_file)

    base_name, ext = os.path.splitext(label_file)
    blurred_label_path = os.path.join(data_path, f"{base_name}_blurred{ext}")

    shutil.copy(label_path, blurred_label_path)

print("Label copying completed!")

"""## randomfog"""

import os
import cv2
from tqdm import tqdm

# 원본 데이터 경로
data_path = '/content/drive/MyDrive/kanghwa/ttt/image_black'

# 파일 리스트 불러오기
file_list = [f for f in os.listdir(data_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

def random_fog(img, fog_intensity=0.4, blur_strength=15):
    # 이미지를 흐리게 만들어 안개 효과를 추가 (중앙에만 흐림 효과를 적용)
    height, width, _ = img.shape
    # 전체 이미지를 흐리게 하기 전에 랜덤하게 선택된 영역에만 흐림 효과를 적용
    mask = np.random.rand(height, width) < fog_intensity  # fog_intensity 확률로 안개 영역 생성
    # 흐림 효과 적용
    foggy_img = cv2.GaussianBlur(img, (blur_strength, blur_strength), 0)
    # 원본 이미지와 흐림 효과가 적용된 이미지 합성 (안개 영역에 흐림 효과 추가)
    img[mask] = foggy_img[mask]
    return img

# Randomfog augmentation 적용
for file_name in tqdm(file_list, desc="Applying random fog augmentation"):
    # 원본 이미지 경로
    img_path = os.path.join(data_path, file_name)

    # 이미지 읽기
    img = cv2.imread(img_path)
    if img is None:
        print(f"Failed to load {file_name}. Skipping...")
        continue

    # 가우시안 블러 적용
    fog_img = random_fog(img, fog_intensity=0.9, blur_strength=55)

    # 블러 처리된 이미지 저장
    base_name, ext = os.path.splitext(file_name)
    fog_output = os.path.join(data_path, f"{base_name}_fog{ext}")
    cv2.imwrite(fog_output, fog_img)

print("Data augmentation completed!")

import os
import shutil
from tqdm import tqdm

# 원본 데이터 경로
data_path = '/content/drive/MyDrive/kanghwa/ttt/labels'

# 라벨 파일 리스트 불러오기
label_files = [f for f in os.listdir(data_path) if f.lower().endswith('.json')]

# 라벨 파일 복사
for label_file in tqdm(label_files, desc="Copying label files"):
    # 원본 라벨 경로
    label_path = os.path.join(data_path, label_file)

    # 복사본 라벨 경로 (_fog 추가)
    base_name, ext = os.path.splitext(label_file)
    fog_label_path = os.path.join(data_path, f"{base_name}_fog{ext}")

    # 라벨 파일 복사
    shutil.copy(label_path, fog_label_path)

print("Label copying completed!")

"""## randomaffine"""

import os
from PIL import Image
from torchvision import transforms
from tqdm import tqdm
import cv2
from google.colab.patches import cv2_imshow  # Colab에서 이미지 출력 시 필요

# 이미지 경로
img_path = '/content/drive/MyDrive/kanghwa/ttt/image_black/40.jpg'

# 이미지 읽기
img = cv2.imread(img_path)
color_jitter = transforms.RandomAffine(20)
if img is None:
    print("Failed to load image. Check the file path.")
else:
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # BGR에서 RGB로 변환
    pil_img = Image.fromarray(img)
    color_img = color_jitter(pil_img)
    # PIL 이미지를 다시 OpenCV 형식으로 변환
    color_img = cv2.cvtColor(np.array(color_img), cv2.COLOR_RGB2BGR)
    # 원본 및 블러 처리된 이미지 출력
    print("Original Image:")
    cv2_imshow(img)

    print("Masked Image:")
    cv2_imshow(color_img)

import os
import cv2
from tqdm import tqdm

# 원본 데이터 경로
data_path = '/content/drive/MyDrive/kanghwa/ttt/image_black'

# 파일 리스트 불러오기
file_list = [f for f in os.listdir(data_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

aff_jitter = transforms.RandomAffine(40)
# Randomfog augmentation 적용
for file_name in tqdm(file_list, desc="Applying random fog augmentation"):
    # 원본 이미지 경로
    img_path = os.path.join(data_path, file_name)

    # 이미지 읽기
    img = cv2.imread(img_path)
    if img is None:
        print(f"Failed to load {file_name}. Skipping...")
        continue

    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    pil_img = Image.fromarray(img)
    aff_img = aff_jitter(pil_img)
    aff_img = cv2.cvtColor(np.array(aff_img), cv2.COLOR_RGB2BGR)

    # 블러 처리된 이미지 저장
    base_name, ext = os.path.splitext(file_name)
    aff_output = os.path.join(data_path, f"{base_name}_affine{ext}")
    cv2.imwrite(aff_output, aff_img)

print("Data augmentation completed!")

"""# Validation ver."""

from sklearn.model_selection import train_test_split
from torch.utils.data import DataLoader
from torchvision import transforms
import torch
from torch.optim.lr_scheduler import StepLR
from torch.optim.lr_scheduler import ExponentialLR
from torch.optim.lr_scheduler import LambdaLR
from torch.optim.lr_scheduler import ReduceLROnPlateau
import matplotlib.pyplot as plt

# 데이터셋 및 데이터로더
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Resize((32,32)),
])

dataset = TicTacToeCellDataset(image_dir='/content/drive/MyDrive/kanghwa/ttt/image_black',
                                label_dir='/content/drive/MyDrive/kanghwa/ttt/labels',
                                transform=transform)

train_dataset, val_dataset = train_test_split(dataset, test_size=0.4)
train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)

# 모델, 손실 함수, 옵티마이저
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = TicTacToeCNN().to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.RMSprop(model.parameters(), lr=0.00035)
scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.95)

# 학습 루프
epochs = 280
train_loss_history = []
val_loss_history = []
for epoch in range(epochs):
    model.train()
    running_train_loss = 0.0

    for inputs, labels in train_dataloader:
        inputs, labels = inputs.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs.view(-1, 3), labels.view(-1).long())
        loss.backward()
        optimizer.step()
        running_train_loss += loss.item()

    scheduler.step()
    epoch_train_loss = running_train_loss / len(train_dataloader)
    train_loss_history.append(epoch_train_loss)

    # Validatio
    model.eval()
    running_val_loss = 0.0

    with torch.no_grad():
        for inputs, labels in val_dataloader:
            inputs, labels = inputs.to(device), labels.to(device)

            outputs = model(inputs)
            loss = criterion(outputs.view(-1, 3), labels.view(-1).long())
            running_val_loss += loss.item()
    epoch_val_loss = running_val_loss / len(val_dataloader)
    val_loss_history.append(epoch_val_loss)

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
plt.plot(range(1, epochs + 1), train_loss_history, label="Training Loss")
plt.plot(range(1, epochs + 1), val_loss_history, label="Validation Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("Training and Validation Loss Over Epochs")
plt.legend()
plt.grid()
plt.show()

"""## model 저장"""

PATH = "/content/drive/MyDrive/kanghwa/ttt/"
torch.save(model.state_dict(), PATH + "model.pt")
torch.save(model.state_dict(), PATH + "model_state_dict.pt") # 모델 객체의 state_dict 저장
torch.save({
    'model' : model.state_dict(),
    'optimizer' : optimizer.state_dict()
}, PATH + 'all.tar') # 여러 가지 값 저장, 학습 중 진행 상황 저장을 위해 epoch, loss 값 등 일반 scalar값 저장 가능

"""# Test Data Labeling"""

import cv2
import os
import json
from google.colab.patches import cv2_imshow

def split_image_into_cells(image_path):
    image = cv2.imread(image_path)
    height, width, _ = image.shape
    cell_height, cell_width = height // 3, width // 3
    cells = [
        image[row * cell_height:(row + 1) * cell_height, col * cell_width:(col + 1) * cell_width]
        for row in range(3)
        for col in range(3)
    ]
    return cells

def label_cells(cells):
    cell_labels = []
    for idx, cell in enumerate(cells):
        cv2_imshow(cell)
        print(f"Label Cell {idx + 1}: (0 for O, 1 for X, 2 for blank)")
        key = input("Enter label (0/1/2):  ")
        if key == '0':
            cell_labels.append("O")
        elif key == '1':
            cell_labels.append("X")
        elif key == '2':
            cell_labels.append("blank")
        else:
            print("Invalid input, defaulting to blank.")
            cell_labels.append("blank")
    return cell_labels

def save_labels_to_json(image_path, labels, output_dir):
    base_name = os.path.basename(image_path).split('.')[0]
    json_path = os.path.join(output_dir, f"{base_name}_labels.json")
    label_data = {f"cell_{i}": label for i, label in enumerate(labels)}
    with open(json_path, 'w') as json_file:
        json.dump(label_data, json_file)
    print(f"Labels saved to {json_path}")

# 라벨링 실행
image_dir = '/content/drive/MyDrive/kanghwa/ttt/image_test'
output_dir = '/content/drive/MyDrive/kanghwa/ttt/labels_test'
os.makedirs(output_dir, exist_ok=True)

for image_file in os.listdir(image_dir):
    if image_file.endswith(('.JPG','.jpg')):
        image_path = os.path.join(image_dir, image_file)
        cells = split_image_into_cells(image_path)
        resized_cells = [cv2.resize(cell, (100,100)) for cell in cells]
        labels = label_cells(cells)
        save_labels_to_json(image_path, labels, output_dir)

"""# Test"""

import torch
import matplotlib.pyplot as plt
import numpy as np
from torchvision import transforms

# 모델을 평가 모드로 전환
model.eval()

# 테스트 데이터셋을 위한 변환 설정 (이미지 전처리)
transform = transforms.Compose([
    transforms.Resize(((32,32))),
    transforms.ToTensor(),
])

# 데이터 로더
test_dataset = TicTacToeCellDataset(image_dir='/content/drive/MyDrive/kanghwa/ttt/image_test', label_dir='/content/drive/MyDrive/kanghwa/ttt/labels_test', transform=transform)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)

# test
correct = 0
total = 0

with torch.no_grad():
    for inputs, labels in test_loader:
        inputs = inputs.to(device)
        labels = labels.to(device)

        outputs = model(inputs)  # (batch_size, 9, 3)
        predicted = torch.argmax(outputs, dim=2)  # (batch_size, 9)
        labels = labels.view(-1, 9)  # (batch_size, 9)

        # 정확도 계산
        total += labels.numel()  # 전체 셀 수 (batch_size * 9)
        correct += (predicted == labels).sum().item()

        # 3x3 형태로 변환
        predicted = predicted.view(-1, 3, 3)  # (batch_size, 3, 3)
        labels = labels.view(-1, 3, 3)        # (batch_size, 3, 3)

        # 시각화
        for i in range(inputs.size(0)):
            plt.figure(figsize=(5, 5))
            plt.imshow(inputs[i].cpu().numpy().transpose(1, 2, 0))
            plt.title(f"Pred: {predicted[i].cpu().numpy()}, Actual: {labels[i].cpu().numpy()}")
            plt.axis("off")
            plt.show()

# 정확도 출력
accuracy = 100 * correct / total
print(f"Test Accuracy: {accuracy:.2f}%")