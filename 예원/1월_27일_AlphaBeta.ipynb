{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "060215d2-7b75-4240-9013-eb91c75f9b5b",
      "metadata": {
        "id": "060215d2-7b75-4240-9013-eb91c75f9b5b"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3a-YBkHhS_l",
        "outputId": "c0f0690e-56db-49aa-90a1-8a3779c5d7cc"
      },
      "id": "F3a-YBkHhS_l",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1999e8fc-6414-4d9b-9aab-baccb5e9e394",
      "metadata": {
        "id": "1999e8fc-6414-4d9b-9aab-baccb5e9e394"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffb90d19-1adb-4a6c-a863-3efdee71eb91",
      "metadata": {
        "id": "ffb90d19-1adb-4a6c-a863-3efdee71eb91"
      },
      "source": [
        "# 00 Game Info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a747d193-2a5d-402f-91df-945a5e38dd01",
      "metadata": {
        "id": "a747d193-2a5d-402f-91df-945a5e38dd01"
      },
      "outputs": [],
      "source": [
        "STATE_SIZE = (3,3) #틱택토 보드 크기\n",
        "N_ACTIONS = STATE_SIZE[0]*STATE_SIZE[1]\n",
        "STATE_DIM = 3 # first player 정보 넣음\n",
        "BOARD_SHAPE = (STATE_DIM, 3, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ef1969c-cb98-45a5-97a6-dfa5e54a0d48",
      "metadata": {
        "id": "3ef1969c-cb98-45a5-97a6-dfa5e54a0d48"
      },
      "source": [
        "# 01 HYPER PARAMS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb9e5db5-2698-4ebd-91ed-c676b0289002",
      "metadata": {
        "id": "cb9e5db5-2698-4ebd-91ed-c676b0289002"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "N_SIMULATIONS = 100  # 각 행동에 대한 시뮬레이션 횟수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6099b13b-076f-4dee-bac1-bf8efb5e7e1c",
      "metadata": {
        "id": "6099b13b-076f-4dee-bac1-bf8efb5e7e1c",
        "outputId": "df9b9fce-968b-4086-f3c4-c5cc9db2cd55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8dcfb6d0-ef59-403f-a07c-23c2e6b8985f",
      "metadata": {
        "id": "8dcfb6d0-ef59-403f-a07c-23c2e6b8985f"
      },
      "source": [
        "# 02 Env+State"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 파일 복사 명령어 실행\n",
        "os.system('cp \"/content/drive/My Drive/Colab Notebooks/공통 environment+state.ipynb\" \"/content/\"')"
      ],
      "metadata": {
        "id": "JSfzV6mxhk_o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b2656cc-479c-4c39-b3e4-1121ef5ba446"
      },
      "id": "JSfzV6mxhk_o",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nbformat\n",
        "\n",
        "notebook_path = \"/content/공통 environment+state.ipynb\"\n",
        "with open(notebook_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    notebook_content = nbformat.read(f, as_version=4)\n",
        "\n",
        "# 각 코드 셀 출력 및 실행\n",
        "for cell in notebook_content.cells:\n",
        "    if cell.cell_type == \"code\":\n",
        "        print(f\"실행 중인 코드:\\n{cell.source}\\n{'='*40}\")\n",
        "        exec(cell.source)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OB9PkizwhnGw",
        "outputId": "ee944815-6a87-49a0-e1ed-90b04a5f4ba0"
      },
      "id": "OB9PkizwhnGw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "실행 중인 코드:\n",
            "import torch\n",
            "import torch.nn as nn\n",
            "import numpy as np\n",
            "========================================\n",
            "실행 중인 코드:\n",
            "STATE_SIZE = (3,3)\n",
            "N_ACTIONS = STATE_SIZE[0]*STATE_SIZE[1]\n",
            "STATE_DIM = 3 # first player 정보 넣음\n",
            "BOARD_SHAPE = (STATE_DIM, 3, 3)\n",
            "========================================\n",
            "실행 중인 코드:\n",
            "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
            "========================================\n",
            "실행 중인 코드:\n",
            "class Environment: #틱택토 게임 환경 정의 클래스 / 게임 규칙을 코드로 구현한 것\n",
            "    def __init__(self):\n",
            "        self.n = STATE_SIZE[0] #보드 행 또는 열 크기\n",
            "        self.num_actions = self.n ** 2\n",
            "        self.action_space = np.arange(self.num_actions)\n",
            "        self.reward_dict = {'win': 1, 'lose': -1, 'draw': 0} #결과에 따른 보상 정의\n",
            "        #승리 1점 / 패배 -1점 / 무승부 0점\n",
            "\n",
            "\n",
            "    def step(self, present_state, action_idx): #현재 상태에서 주어진 행동에 따라 게임 진행 / 행동 결과를 계산\n",
            "        \"\"\"\n",
            "        present_state에 대해 action_idx의 행동에 따라 게임을 한 턴 진행시키고\n",
            "        next_state, is_done, is_lose를 반환한다.\n",
            "        \"\"\"\n",
            "        #action_idx: 플레이어가 선택한 행동의 인덱스 / 보드 칸\n",
            "        #현재 상태에서 행동하는 행동을 수행하여 다음 상태를 계산\n",
            "        next_state = present_state.next(action_idx)\n",
            "        is_done, is_lose = next_state.check_done()\n",
            "        #next_state에서 게임이 종료되었는지 확인\n",
            "        #현재 플레이어가 패배했는지 확인\n",
            "\n",
            "        return next_state, is_done, is_lose\n",
            "\n",
            "\n",
            "    def get_reward(self, final_state): #게임 종료 후 보상 계산 / 승패 및 무승부 판정\n",
            "        \"\"\"\n",
            "        게임이 종료된 state에 대해 각 플레이어의 reward를 반환한다.\n",
            "        final_state: 게임이 종료된 state\n",
            "        note: final_state가 is_lose라면, 해당 state에서 행동할 차례였던 플레이어가 패배한 것.\n",
            "        \"\"\"\n",
            "        '''\n",
            "        장예원 수정!\n",
            "        '''\n",
            "        is_done, is_lose = final_state.check_done()  # 게임 종료 및 패배 여부 확인\n",
            "\n",
            "        # 승리, 패배, 무승부 정확하게 판별\n",
            "        if not is_done:\n",
            "            return 0  # 게임이 아직 끝나지 않았으면 보상을 주지 않음\n",
            "\n",
            "        if is_lose:\n",
            "            return self.reward_dict['lose']  # 패배 시 -1\n",
            "\n",
            "        if final_state.total_pieces_count() == self.num_actions:\n",
            "            return self.reward_dict['draw']  # 무승부 시 0\n",
            "\n",
            "        return self.reward_dict['win']  # 승리 시 +1\n",
            "\n",
            "\n",
            "    def render(self, state): #게임 상태 출력\n",
            "        '''\n",
            "        입력받은 state를 문자열로 출력한다.\n",
            "        X: first_player, O: second_player\n",
            "        '''\n",
            "        is_first_player = state.check_first_player() #현재 차례가 첫번째 플레이어인지 확인\n",
            "        board = state.state - state.enemy_state if is_first_player else state.enemy_state - state.state\n",
            "        board = board.reshape(3,3) #현재 보드 상태를 정리\n",
            "\n",
            "        board_list = [['X' if cell == 1 else 'O' if cell == -1 else '.' for cell in row] for row in board]\n",
            "        #돌 상태를 문자로 변환 -> 읽기 쉽게 표시\n",
            "        #X: 첫번째 플레이어의 돌 / O: 두번째 플레이어의 돌 / .: 빈칸\n",
            "        formatted_board = \"\\n\".join([\" \".join(row) for row in board_list])\n",
            "        #보기 좋게 줄바꿈하여 출력\n",
            "        return formatted_board  #print() 대신 문자열 반환\n",
            "========================================\n",
            "실행 중인 코드:\n",
            "import copy\n",
            "========================================\n",
            "실행 중인 코드:\n",
            "class State(Environment):\n",
            "    def __init__(self, state=None, enemy_state=None):\n",
            "        super().__init__()\n",
            "        self.state = state if state is not None else [0] * (self.n ** 2)\n",
            "        self.enemy_state = enemy_state if enemy_state is not None else [0] * (self.n ** 2)\n",
            "\n",
            "        self.state = np.array(self.state).reshape(STATE_SIZE)\n",
            "        self.enemy_state = np.array(self.enemy_state).reshape(STATE_SIZE)\n",
            "        self.move_count = 0 # 초기 상태에서 Player 1이 선공\n",
            "\n",
            "\n",
            "    def total_pieces_count(self):\n",
            "        '''\n",
            "        이 state의 전체 돌의 개수를 반환한다.\n",
            "        '''\n",
            "        total_state = self.state + self.enemy_state\n",
            "        return np.sum(total_state)\n",
            "\n",
            "\n",
            "    def get_legal_actions(self):\n",
            "        '''\n",
            "        이 state에서 가능한 action을\n",
            "        one-hot encoding 형식의 array로 반환한다.\n",
            "        '''\n",
            "        total_state = (self.state + self.enemy_state).reshape(-1)\n",
            "        legal_actions = np.array([total_state[x] == 0 for x in self.action_space], dtype = int)\n",
            "        return legal_actions\n",
            "\n",
            "\n",
            "    def check_done(self):\n",
            "        '''\n",
            "        이 state의 done, lose 여부를 반환한다.\n",
            "        note: 상대가 행동한 후, 자신의 행동을 하기 전 이 state를 확인한다.\n",
            "        따라서 이전 state에서 상대의 행동으로 상대가 이긴 경우는 이 state의 플레이어가 진 경우이다.\n",
            "        '''\n",
            "        is_done, is_lose = False, False\n",
            "\n",
            "        # Check draw\n",
            "        if self.total_pieces_count() == self.n ** 2:\n",
            "            is_done, is_lose = True, False\n",
            "\n",
            "        # Check lose\n",
            "        lose_condition = np.concatenate([self.enemy_state.sum(axis=0), self.enemy_state.sum(axis=1), [self.enemy_state.trace], [np.fliplr(self.enemy_state).trace()]])\n",
            "        if self.n in lose_condition:\n",
            "            is_done, is_lose = True, True\n",
            "\n",
            "        return is_done, is_lose\n",
            "\n",
            "\n",
            "    def next(self, action_idx):\n",
            "        '''\n",
            "        주어진 action에 따라 다음 state를 생성한다.\n",
            "        note: 다음 state는 상대의 차례이므로 state 순서를 바꾼다.\n",
            "        '''\n",
            "        x, y =np.divmod(action_idx, self.n)\n",
            "        state = self.state.copy()\n",
            "        state[x, y] = 1\n",
            "\n",
            "        state = list(state.reshape(-1))\n",
            "        enemy_state = list(copy.copy(self.enemy_state).reshape(-1))\n",
            "\n",
            "        next_state = State(enemy_state, state)  # state와 enemy_state를 바꿔서 전달\n",
            "        next_state.move_count = self.move_count + 1  # move_count 증가\n",
            "        return next_state\n",
            "\n",
            "\n",
            "    def check_first_player(self):\n",
            "        # State()를 기본적으로 생성하면 move_count = 0이므로 check_first_player()는 항상 True\n",
            "        return self.move_count % 2 == 0\n",
            "\n",
            "\n",
            "    def get_random_action(self):\n",
            "        '''\n",
            "        이 state에서 가능한 action 중 랜덤으로 action을 반환한다.\n",
            "        '''\n",
            "        legal_actions = self.get_legal_actions()\n",
            "        legal_action_idxs = np.where(legal_actions != 0)[0]\n",
            "        action = np.random.choice(legal_action_idxs)\n",
            "        return action\n",
            "\n",
            "\n",
            "    def __str__(self):\n",
            "        return Environment().render(self)  # state를 인자로 명확히 전달\n",
            "========================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bc1cecc-9934-4d03-81ea-b7b80b938d46",
      "metadata": {
        "id": "4bc1cecc-9934-4d03-81ea-b7b80b938d46"
      },
      "source": [
        "# 03 AlphaBeta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea7b9ed8-7fc9-4c1a-a7a7-1236ecdef7ef",
      "metadata": {
        "id": "ea7b9ed8-7fc9-4c1a-a7a7-1236ecdef7ef"
      },
      "outputs": [],
      "source": [
        "class AlphaBetaAgent:\n",
        "    def __init__(self, depth=3):\n",
        "        self.depth = depth\n",
        "\n",
        "\n",
        "    def get_action(self, state): # 현재 상태에서 최적의 행동 선택\n",
        "        _, best_action = self._alphabeta(state, self.depth, -float('inf'), float('inf'), True)\n",
        "\n",
        "        if best_action is None:  # 가능한 행동이 없을 경우 예외 처리 통해 랜덤 선택\n",
        "            legal_actions = np.where(state.get_legal_actions() != 0)[0]\n",
        "            if len(legal_actions) > 0:\n",
        "                print(\"[WARNING] No optimal actions found, choosing a random action.\")\n",
        "                return np.random.choice(legal_actions)  # 가능한 행동 중 랜덤 선택\n",
        "            else:\n",
        "                print(\"[ERROR] No valid actions available. Game might be in an invalid state.\")\n",
        "                return None  # 안전하게 None 반환\n",
        "\n",
        "        return best_action\n",
        "\n",
        "\n",
        "    # AlphaBeta 탐색 알고리즘의 재귀 구현\n",
        "    def _alphabeta(self, state, depth, alpha, beta, is_maximizing_player):\n",
        "        # 종료 조건: 게임이 끝났거나 탐색 깊이에 도달한 경우\n",
        "        is_done, is_lose = state.check_done()\n",
        "        if is_done or depth == 0 or len(np.where(state.get_legal_actions() != 0)[0]) == 0:\n",
        "            return self._evaluate_state(state), None\n",
        "\n",
        "        legal_actions = np.where(state.get_legal_actions() != 0)[0]\n",
        "\n",
        "        if is_maximizing_player:\n",
        "            max_eval = -float('inf')\n",
        "            best_action = None\n",
        "            for action in legal_actions:\n",
        "                next_state = state.next(action)\n",
        "                eval_value, _ = self._alphabeta(next_state, depth - 1, alpha, beta, False)\n",
        "\n",
        "                # 가지치기 수행\n",
        "                if eval_value >= beta:\n",
        "                    return eval_value, action  #가지치기 발생 즉시 반환\n",
        "\n",
        "                if eval_value > max_eval:\n",
        "                    max_eval = eval_value\n",
        "                    best_action = action\n",
        "\n",
        "                alpha = max(alpha, eval_value)\n",
        "\n",
        "            return max_eval, best_action\n",
        "        else:\n",
        "            min_eval = float('inf')\n",
        "            best_action = None\n",
        "            for action in legal_actions:\n",
        "                next_state = state.next(action)\n",
        "                eval_value, _ = self._alphabeta(next_state, depth - 1, alpha, beta, True)\n",
        "\n",
        "                # 가지치기 수행\n",
        "                if eval_value <= alpha:\n",
        "                    return eval_value, action  # 가지치기 발생 즉시 반환\n",
        "\n",
        "                if eval_value < min_eval:\n",
        "                    min_eval = eval_value\n",
        "                    best_action = action\n",
        "\n",
        "                beta = min(beta, eval_value)\n",
        "\n",
        "            return min_eval, best_action\n",
        "\n",
        "\n",
        "    def _evaluate_state(self, state):  # 상태 평가 함수\n",
        "       if state.check_done()[0]:  # 종료 상태라면 보상 반환\n",
        "           return state.get_reward(state)\n",
        "\n",
        "       # 개선된 평가 기준 (새로운 변수를 만들지 않음)\n",
        "       return (\n",
        "           (np.sum(state.state) - np.sum(state.enemy_state)) * 0.5  # 플레이어 돌 개수 차이\n",
        "           + (np.sum(state.state == 1, axis=0).max() == 2) * 1.0  # 가로 2개 연속 여부\n",
        "           + (np.sum(state.state == 1, axis=1).max() == 2) * 1.0  # 세로 2개 연속 여부\n",
        "           + (np.trace(state.state) == 2) * 1.0  # 대각선 (\\) 2개 연속 여부\n",
        "           + (np.trace(np.fliplr(state.state)) == 2) * 1.0  # 대각선 (/) 2개 연속 여부\n",
        "       )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "578224a6-84c6-4d1b-bd86-36a8c858c7ad",
      "metadata": {
        "id": "578224a6-84c6-4d1b-bd86-36a8c858c7ad"
      },
      "source": [
        "## Test Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08a965d2-f452-497c-91b9-d449fe9c8a9f",
      "metadata": {
        "id": "08a965d2-f452-497c-91b9-d449fe9c8a9f",
        "outputId": "78e67ccb-ec37-4097-ba22-b21c3265478e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "초기 상태 보드:\n",
            "가능한 행동들: [0 1 2 3 4 5 6 7 8]\n"
          ]
        }
      ],
      "source": [
        "# 1. State 초기화\n",
        "state = State()\n",
        "print(\"초기 상태 보드:\")\n",
        "state.render(state)\n",
        "print(\"가능한 행동들:\", np.where(state.get_legal_actions() != 0)[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2262ad5-6bdc-44ab-86b8-3899ef3c9fc0",
      "metadata": {
        "id": "e2262ad5-6bdc-44ab-86b8-3899ef3c9fc0"
      },
      "outputs": [],
      "source": [
        "# 2. AlphaBeta 초기화\n",
        "alpha_beta = AlphaBetaAgent(depth=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfec90d0-7c3b-49bc-9381-a0306a349f8c",
      "metadata": {
        "id": "bfec90d0-7c3b-49bc-9381-a0306a349f8c",
        "outputId": "80722980-b8a1-45fd-9d54-1b353e70151b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AlphaBeta 탐색이 선택한 최적 행동: 0\n"
          ]
        }
      ],
      "source": [
        "# 3. 최적 행동 확인\n",
        "best_action = alpha_beta.get_action(state)\n",
        "print(\"AlphaBeta 탐색이 선택한 최적 행동:\", best_action)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab769045-de4d-4f8c-b5ad-4f2cc18e1bfa",
      "metadata": {
        "id": "ab769045-de4d-4f8c-b5ad-4f2cc18e1bfa",
        "outputId": "6d014913-765e-4988-ee3e-064c38631099",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 상태 보드:\n",
            "가능한 행동들: [0 4 6 7 8]\n",
            "테스트 상태에서 AlphaBeta 선택 행동: 8\n"
          ]
        }
      ],
      "source": [
        "# 4. 특정 상태 테스트\n",
        "custom_state = State()\n",
        "custom_state = custom_state.next(3)  # 첫 번째 플레이어가 3번 칸에 놓음\n",
        "custom_state = custom_state.next(5)  # 두 번째 플레이어가 5번 칸에 놓음\n",
        "custom_state = custom_state.next(1)  # 첫 번째 플레이어가 1번 칸에 놓음\n",
        "custom_state = custom_state.next(2)  # 두 번째 플레이어가 2번 칸에 놓음\n",
        "\n",
        "print(\"테스트 상태 보드:\")\n",
        "custom_state.render(custom_state)\n",
        "print(\"가능한 행동들:\", np.where(custom_state.get_legal_actions() != 0)[0])\n",
        "\n",
        "best_action_test = alpha_beta.get_action(custom_state)\n",
        "print(\"테스트 상태에서 AlphaBeta 선택 행동:\", best_action_test)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}